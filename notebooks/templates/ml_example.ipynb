{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PySpark Machine Learning Example ðŸ¤–\n",
                "\n",
                "This notebook demonstrates a simple machine learning workflow using PySpark MLlib."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "from pyspark.sql import SparkSession\n",
                "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
                "from pyspark.ml.regression import LinearRegression\n",
                "from pyspark.ml.evaluation import RegressionEvaluator\n",
                "\n",
                "# Initialize Spark\n",
                "spark = SparkSession.builder \\\n",
                "    .appName('ML Example') \\\n",
                "    .master('spark://spark-master:7077') \\\n",
                "    .getOrCreate()\n",
                "\n",
                "print('Spark session initialized!')"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Sample Dataset\n",
                "\n",
                "Let's create a simple dataset to predict house prices based on features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Sample house data: (bedrooms, bathrooms, sqft, age, price)\n",
                "data = [\n",
                "    (3, 2, 1500, 10, 300000),\n",
                "    (4, 3, 2000, 5, 450000),\n",
                "    (2, 1, 1000, 20, 200000),\n",
                "    (5, 4, 3000, 2, 650000),\n",
                "    (3, 2, 1600, 12, 320000),\n",
                "    (4, 2, 1800, 8, 380000),\n",
                "    (2, 2, 1200, 15, 250000),\n",
                "    (3, 3, 1700, 7, 350000),\n",
                "    (4, 3, 2200, 4, 480000),\n",
                "    (5, 3, 2500, 6, 550000),\n",
                "    (3, 2, 1550, 11, 310000),\n",
                "    (4, 2, 1900, 9, 400000),\n",
                "    (2, 1, 950, 25, 180000),\n",
                "    (6, 4, 3500, 1, 750000),\n",
                "    (3, 2, 1450, 13, 290000)\n",
                "]\n",
                "\n",
                "columns = ['bedrooms', 'bathrooms', 'sqft', 'age', 'price']\n",
                "df = spark.createDataFrame(data, columns)\n",
                "\n",
                "df.show()\n",
                "df.describe().show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Feature Engineering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Prepare features\n",
                "feature_columns = ['bedrooms', 'bathrooms', 'sqft', 'age']\n",
                "\n",
                "# Assemble features into a single vector\n",
                "assembler = VectorAssembler(\n",
                "    inputCols=feature_columns,\n",
                "    outputCol='raw_features'\n",
                ")\n",
                "\n",
                "df_assembled = assembler.transform(df)\n",
                "\n",
                "# Scale features\n",
                "scaler = StandardScaler(\n",
                "    inputCol='raw_features',\n",
                "    outputCol='features',\n",
                "    withStd=True,\n",
                "    withMean=True\n",
                ")\n",
                "\n",
                "scaler_model = scaler.fit(df_assembled)\n",
                "df_scaled = scaler_model.transform(df_assembled)\n",
                "\n",
                "df_scaled.select('features', 'price').show(5, truncate=False)"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Split Data into Train and Test Sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Split data: 80% training, 20% testing\n",
                "train_data, test_data = df_scaled.randomSplit([0.8, 0.2], seed=42)\n",
                "\n",
                "print(f'Training set size: {train_data.count()}')\n",
                "print(f'Test set size: {test_data.count()}')"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Train Linear Regression Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Create Linear Regression model\n",
                "lr = LinearRegression(\n",
                "    featuresCol='features',\n",
                "    labelCol='price',\n",
                "    maxIter=100,\n",
                "    regParam=0.1,\n",
                "    elasticNetParam=0.8\n",
                ")\n",
                "\n",
                "# Train the model\n",
                "lr_model = lr.fit(train_data)\n",
                "\n",
                "print('Model trained successfully!')\n",
                "print(f'Coefficients: {lr_model.coefficients}')\n",
                "print(f'Intercept: {lr_model.intercept}')"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Make Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Make predictions on test data\n",
                "predictions = lr_model.transform(test_data)\n",
                "\n",
                "# Show predictions\n",
                "predictions.select(\n",
                "    'bedrooms', 'bathrooms', 'sqft', 'age', \n",
                "    'price', 'prediction'\n",
                ").show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Evaluate Model Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Create evaluator\n",
                "evaluator = RegressionEvaluator(\n",
                "    labelCol='price',\n",
                "    predictionCol='prediction'\n",
                ")\n",
                "\n",
                "# Calculate metrics\n",
                "rmse = evaluator.evaluate(predictions, {evaluator.metricName: 'rmse'})\n",
                "mae = evaluator.evaluate(predictions, {evaluator.metricName: 'mae'})\n",
                "r2 = evaluator.evaluate(predictions, {evaluator.metricName: 'r2'})\n",
                "\n",
                "print(f'Root Mean Squared Error (RMSE): ${rmse:,.2f}')\n",
                "print(f'Mean Absolute Error (MAE): ${mae:,.2f}')\n",
                "print(f'R-squared (R2): {r2:.4f}')\n",
                "\n",
                "# Training summary\n",
                "training_summary = lr_model.summary\n",
                "print(f'\\nTraining RMSE: ${training_summary.rootMeanSquaredError:,.2f}')\n",
                "print(f'Training R2: {training_summary.r2:.4f}')"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Make Predictions on New Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# New house to predict\n",
                "new_house = [\n",
                "    (4, 3, 2100, 7, 0)  # price is unknown, set to 0\n",
                "]\n",
                "\n",
                "new_df = spark.createDataFrame(new_house, columns)\n",
                "\n",
                "# Apply same transformations\n",
                "new_assembled = assembler.transform(new_df)\n",
                "new_scaled = scaler_model.transform(new_assembled)\n",
                "\n",
                "# Predict\n",
                "new_prediction = lr_model.transform(new_scaled)\n",
                "\n",
                "predicted_price = new_prediction.select('prediction').first()[0]\n",
                "print(f'\\nPredicted price for new house: ${predicted_price:,.2f}')"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "In this notebook, we:\n",
                "1. Created a sample dataset\n",
                "2. Performed feature engineering (assembly and scaling)\n",
                "3. Split data into training and test sets\n",
                "4. Trained a Linear Regression model\n",
                "5. Made predictions\n",
                "6. Evaluated model performance\n",
                "7. Used the model to predict prices for new houses\n",
                "\n",
                "Next steps:\n",
                "- Try other algorithms (Decision Trees, Random Forest, Gradient Boosting)\n",
                "- Perform hyperparameter tuning\n",
                "- Add more features\n",
                "- Handle categorical variables"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}