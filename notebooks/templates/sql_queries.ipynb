{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PySpark SQL Queries ðŸ”\n",
                "\n",
                "This notebook demonstrates how to use SQL queries in PySpark."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "from pyspark.sql import SparkSession\n",
                "\n",
                "# Initialize Spark with SQL support\n",
                "spark = SparkSession.builder \\\n",
                "    .appName('SQL Queries') \\\n",
                "    .master('spark://spark-master:7077') \\\n",
                "    .getOrCreate()\n",
                "\n",
                "print('Spark session initialized with SQL support!')"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create Sample Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Customer data\n",
                "customers = [\n",
                "    (1, 'Alice', 'New York', 'Premium'),\n",
                "    (2, 'Bob', 'Los Angeles', 'Standard'),\n",
                "    (3, 'Charlie', 'Chicago', 'Premium'),\n",
                "    (4, 'Diana', 'Houston', 'Standard'),\n",
                "    (5, 'Eve', 'Phoenix', 'Premium')\n",
                "]\n",
                "\n",
                "# Orders data\n",
                "orders = [\n",
                "    (101, 1, 250.50, '2024-01-15'),\n",
                "    (102, 2, 150.75, '2024-01-16'),\n",
                "    (103, 1, 320.00, '2024-01-17'),\n",
                "    (104, 3, 450.25, '2024-01-18'),\n",
                "    (105, 2, 180.00, '2024-01-19'),\n",
                "    (106, 4, 275.50, '2024-01-20'),\n",
                "    (107, 1, 200.00, '2024-01-21'),\n",
                "    (108, 5, 350.75, '2024-01-22')\n",
                "]\n",
                "\n",
                "# Create DataFrames\n",
                "customers_df = spark.createDataFrame(\n",
                "    customers, \n",
                "    ['customer_id', 'name', 'city', 'membership']\n",
                ")\n",
                "\n",
                "orders_df = spark.createDataFrame(\n",
                "    orders, \n",
                "    ['order_id', 'customer_id', 'amount', 'order_date']\n",
                ")\n",
                "\n",
                "customers_df.show()\n",
                "orders_df.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Register Tables for SQL Queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Register DataFrames as temporary views\n",
                "customers_df.createOrReplaceTempView('customers')\n",
                "orders_df.createOrReplaceTempView('orders')\n",
                "\n",
                "print('Tables registered successfully!')"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Basic SQL Queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# SELECT all customers\n",
                "spark.sql('SELECT * FROM customers').show()\n",
                "\n",
                "# SELECT with WHERE clause\n",
                "premium = spark.sql(\"\"\"\n",
                "    SELECT name, city \n",
                "    FROM customers \n",
                "    WHERE membership = 'Premium'\n",
                "\"\"\")\n",
                "premium.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Aggregation Queries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Count orders per customer\n",
                "order_counts = spark.sql(\"\"\"\n",
                "    SELECT customer_id, COUNT(*) as order_count\n",
                "    FROM orders\n",
                "    GROUP BY customer_id\n",
                "    ORDER BY order_count DESC\n",
                "\"\"\")\n",
                "order_counts.show()\n",
                "\n",
                "# Total revenue per customer\n",
                "customer_revenue = spark.sql(\"\"\"\n",
                "    SELECT \n",
                "        customer_id,\n",
                "        COUNT(*) as total_orders,\n",
                "        SUM(amount) as total_spent,\n",
                "        AVG(amount) as avg_order_value\n",
                "    FROM orders\n",
                "    GROUP BY customer_id\n",
                "    ORDER BY total_spent DESC\n",
                "\"\"\")\n",
                "customer_revenue.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## JOIN Operations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# INNER JOIN: Customer names with their orders\n",
                "customer_orders = spark.sql(\"\"\"\n",
                "    SELECT \n",
                "        c.name,\n",
                "        c.city,\n",
                "        c.membership,\n",
                "        o.order_id,\n",
                "        o.amount,\n",
                "        o.order_date\n",
                "    FROM customers c\n",
                "    INNER JOIN orders o ON c.customer_id = o.customer_id\n",
                "    ORDER BY o.order_date\n",
                "\"\"\")\n",
                "customer_orders.show()\n",
                "\n",
                "# Aggregated JOIN\n",
                "customer_summary = spark.sql(\"\"\"\n",
                "    SELECT \n",
                "        c.name,\n",
                "        c.membership,\n",
                "        COUNT(o.order_id) as total_orders,\n",
                "        ROUND(SUM(o.amount), 2) as total_spent\n",
                "    FROM customers c\n",
                "    LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
                "    GROUP BY c.name, c.membership\n",
                "    ORDER BY total_spent DESC\n",
                "\"\"\")\n",
                "customer_summary.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Subqueries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Customers with above-average spending\n",
                "high_spenders = spark.sql(\"\"\"\n",
                "    SELECT \n",
                "        c.name,\n",
                "        SUM(o.amount) as total_spent\n",
                "    FROM customers c\n",
                "    JOIN orders o ON c.customer_id = o.customer_id\n",
                "    GROUP BY c.name\n",
                "    HAVING SUM(o.amount) > (\n",
                "        SELECT AVG(customer_total)\n",
                "        FROM (\n",
                "            SELECT SUM(amount) as customer_total\n",
                "            FROM orders\n",
                "            GROUP BY customer_id\n",
                "        )\n",
                "    )\n",
                "\"\"\")\n",
                "high_spenders.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Window Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Rank orders by amount within each customer\n",
                "ranked_orders = spark.sql(\"\"\"\n",
                "    SELECT \n",
                "        customer_id,\n",
                "        order_id,\n",
                "        amount,\n",
                "        RANK() OVER (PARTITION BY customer_id ORDER BY amount DESC) as rank\n",
                "    FROM orders\n",
                "    ORDER BY customer_id, rank\n",
                "\"\"\")\n",
                "ranked_orders.show()\n",
                "\n",
                "# Running total\n",
                "running_total = spark.sql(\"\"\"\n",
                "    SELECT \n",
                "        order_date,\n",
                "        amount,\n",
                "        SUM(amount) OVER (ORDER BY order_date) as running_total\n",
                "    FROM orders\n",
                "    ORDER BY order_date\n",
                "\"\"\")\n",
                "running_total.show()"
            ],
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save Query Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Save customer summary to parquet\n",
                "# customer_summary.write.mode('overwrite').parquet('/home/jovyan/data/customer_summary.parquet')\n",
                "\n",
                "print('SQL queries completed!')"
            ],
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}